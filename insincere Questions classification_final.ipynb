{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10737,"databundleVersionId":290346,"sourceType":"competition"},{"sourceId":30643,"sourceType":"modelInstanceVersion","modelInstanceId":25736},{"sourceId":30649,"sourceType":"modelInstanceVersion","modelInstanceId":25741},{"sourceId":30650,"sourceType":"modelInstanceVersion","modelInstanceId":25742}],"dockerImageVersionId":30683,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-13T21:32:44.188811Z","iopub.execute_input":"2024-04-13T21:32:44.189171Z","iopub.status.idle":"2024-04-13T21:32:45.042774Z","shell.execute_reply.started":"2024-04-13T21:32:44.189125Z","shell.execute_reply":"2024-04-13T21:32:45.041895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom transformers import BertTokenizer, BertModel\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nfrom tqdm import tqdm\n\nfrom sklearn.utils.class_weight import compute_class_weight\nimport torch.utils\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim.lr_scheduler import MultiStepLR","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:32:45.044455Z","iopub.execute_input":"2024-04-13T21:32:45.044918Z","iopub.status.idle":"2024-04-13T21:32:52.609083Z","shell.execute_reply.started":"2024-04-13T21:32:45.044885Z","shell.execute_reply":"2024-04-13T21:32:52.608312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:32:52.610781Z","iopub.execute_input":"2024-04-13T21:32:52.611564Z","iopub.status.idle":"2024-04-13T21:32:52.643020Z","shell.execute_reply.started":"2024-04-13T21:32:52.611531Z","shell.execute_reply":"2024-04-13T21:32:52.642103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/quora-insincere-questions-classification/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/quora-insincere-questions-classification/test.csv\")\nsub_df = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:32:52.644281Z","iopub.execute_input":"2024-04-13T21:32:52.644549Z","iopub.status.idle":"2024-04-13T21:32:58.429090Z","shell.execute_reply.started":"2024-04-13T21:32:52.644526Z","shell.execute_reply":"2024-04-13T21:32:58.428298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, question_text,targets, tokenizer, max_length=60):\n        self.texts = question_text\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        target = float(self.targets[idx])\n        encoding = self.tokenizer.encode_plus(\n            text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            add_special_tokens=True,\n            return_tensors='pt'\n        )\n        return (encoding['input_ids'].flatten(), encoding['attention_mask'].flatten(),torch.tensor(target))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:32:58.431115Z","iopub.execute_input":"2024-04-13T21:32:58.431435Z","iopub.status.idle":"2024-04-13T21:32:58.438430Z","shell.execute_reply.started":"2024-04-13T21:32:58.431410Z","shell.execute_reply":"2024-04-13T21:32:58.437544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self,df_test, tokenizer, max_length = 60):\n        self.texts = df_test.question_text\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self,idx):\n        text = str(self.texts[idx])\n        encoding = self.tokenizer.encode_plus(\n        text,\n        max_length = self.max_length,\n        padding = 'max_length',\n        truncation = True,\n        add_special_tokens = True,\n        return_tensors = 'pt'\n        )\n        return (encoding['input_ids'].flatten(),encoding['attention_mask'].flatten())","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:32:58.439662Z","iopub.execute_input":"2024-04-13T21:32:58.440274Z","iopub.status.idle":"2024-04-13T21:32:58.453015Z","shell.execute_reply.started":"2024-04-13T21:32:58.440240Z","shell.execute_reply":"2024-04-13T21:32:58.452235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_tokenizer = torch.load('/kaggle/input/bert_tokenizer/pytorch/1.01/1/Bert Tokenizer.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:32:58.454014Z","iopub.execute_input":"2024-04-13T21:32:58.454283Z","iopub.status.idle":"2024-04-13T21:32:58.542577Z","shell.execute_reply.started":"2024-04-13T21:32:58.454261Z","shell.execute_reply":"2024-04-13T21:32:58.541520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained BERT tokenizer\n# bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:39:35.624304Z","iopub.execute_input":"2024-04-13T19:39:35.624596Z","iopub.status.idle":"2024-04-13T19:39:35.628503Z","shell.execute_reply.started":"2024-04-13T19:39:35.624570Z","shell.execute_reply":"2024-04-13T19:39:35.627659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_inputs, val_inputs,train_targets, val_targets = train_test_split(df_train.question_text, df_train.target,stratify=df_train.target,test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:39:35.629646Z","iopub.execute_input":"2024-04-13T19:39:35.630455Z","iopub.status.idle":"2024-04-13T19:39:35.637869Z","shell.execute_reply.started":"2024-04-13T19:39:35.630431Z","shell.execute_reply":"2024-04-13T19:39:35.637149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_inputs.reset_index(drop=True,inplace=True)\n# train_targets.reset_index(drop=True,inplace=True)\n# val_targets.reset_index(drop=True,inplace=True)\n# val_inputs.reset_index(drop=True,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:39:35.638804Z","iopub.execute_input":"2024-04-13T19:39:35.639051Z","iopub.status.idle":"2024-04-13T19:39:35.647999Z","shell.execute_reply.started":"2024-04-13T19:39:35.639029Z","shell.execute_reply":"2024-04-13T19:39:35.647128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_ds = TrainDataset(train_inputs,train_targets,bert_tokenizer)\n# val_ds = TrainDataset(val_inputs,val_targets,bert_tokenizer)\n# train_dl = DataLoader(train_ds,  batch_size=256)\n# val_dl = DataLoader(val_ds, batch_size=512)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:39:35.650504Z","iopub.execute_input":"2024-04-13T19:39:35.650769Z","iopub.status.idle":"2024-04-13T19:39:35.657445Z","shell.execute_reply.started":"2024-04-13T19:39:35.650747Z","shell.execute_reply":"2024-04-13T19:39:35.656666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class BERT_MODEL(nn.Module):\n#     def __init__(self):\n#         super(BERT_MODEL,self).__init__()\n#         self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n#         self.linear = nn.Sequential(\n#         nn.Linear(768,1024),\n#         nn.ReLU(),\n#         nn.Dropout(0.3),\n#         nn.Linear(1024,1)\n#         )\n    \n#     def forward(self,input_ids,attention_mask):   \n#         output = self.bert_model(input_ids = input_ids,attention_mask = attention_mask)\n#         pooled_output = output.pooler_output\n#         output = self.linear(pooled_output)\n#         return output","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:39:35.658359Z","iopub.execute_input":"2024-04-13T19:39:35.660004Z","iopub.status.idle":"2024-04-13T19:39:35.669295Z","shell.execute_reply.started":"2024-04-13T19:39:35.659980Z","shell.execute_reply":"2024-04-13T19:39:35.668554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERT_MODEL(nn.Module):\n    def __init__(self):\n        super(BERT_MODEL,self).__init__()\n        self.bert_model = torch.load('/kaggle/input/bert-base-uncased/pytorch/1.01/1/BertModel_base_uncased.pth')\n        self.linear = nn.Sequential(\n        nn.Linear(768,1024),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(1024,1)\n        )\n    \n    def forward(self,input_ids,attention_mask):   \n        output = self.bert_model(input_ids = input_ids,attention_mask = attention_mask)\n        pooled_output = output.pooler_output\n        output = self.linear(pooled_output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:32:58.543928Z","iopub.execute_input":"2024-04-13T21:32:58.544239Z","iopub.status.idle":"2024-04-13T21:32:58.552441Z","shell.execute_reply.started":"2024-04-13T21:32:58.544215Z","shell.execute_reply":"2024-04-13T21:32:58.551402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = BERT_MODEL()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:22:42.196924Z","iopub.execute_input":"2024-04-13T19:22:42.197358Z","iopub.status.idle":"2024-04-13T19:22:42.205818Z","shell.execute_reply.started":"2024-04-13T19:22:42.197332Z","shell.execute_reply":"2024-04-13T19:22:42.204991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:22:42.206703Z","iopub.execute_input":"2024-04-13T19:22:42.206949Z","iopub.status.idle":"2024-04-13T19:22:42.215744Z","shell.execute_reply.started":"2024-04-13T19:22:42.206927Z","shell.execute_reply":"2024-04-13T19:22:42.214867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def find_best_f1(outputs, labels):\n#     tmp = [0, 0, 0]  # idx, cur, max\n#     threshold = 0\n\n#     for tmp[0] in np.arange(0.1, 0.99, 0.01):\n#         tmp[1] = f1_score(labels, outputs > tmp[0])\n#         if tmp[1] > tmp[2]:\n#             threshold = tmp[0]\n#             tmp[2] = tmp[1]\n\n#     return tmp[2], threshold","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:18:23.664304Z","iopub.execute_input":"2024-04-13T19:18:23.665092Z","iopub.status.idle":"2024-04-13T19:18:23.669704Z","shell.execute_reply.started":"2024-04-13T19:18:23.665038Z","shell.execute_reply":"2024-04-13T19:18:23.668402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_preds(logits,threshold):\n    \n#     # Convert logits to binary predictions based on the threshold\n#     predictions = (torch.sigmoid(logits) > threshold).float()\n    \n#     return predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:18:24.158107Z","iopub.execute_input":"2024-04-13T19:18:24.158695Z","iopub.status.idle":"2024-04-13T19:18:24.162839Z","shell.execute_reply.started":"2024-04-13T19:18:24.158667Z","shell.execute_reply":"2024-04-13T19:18:24.161826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def evaluate(model,val_dl):\n#     losses=[]\n#     val_outputs = []\n#     val_targets = []\n#     accuracy = []\n#     f1 = []\n#     i=1\n#     model.eval()\n#     with torch.no_grad():\n#         for batch in tqdm(val_dl):\n#             input_ids,attention_mask, targets = batch\n#             input_ids = input_ids.to(device)\n#             attention_mask = attention_mask.to(device)\n#             targets = targets.to(device)## target is of type 0.0 and 1.0\n            \n#             output = model(input_ids,attention_mask)\n            \n#             loss = BCE(output.squeeze(), targets.float())\n            \n#             val_outputs.append(torch.sigmoid(output).squeeze().cpu().numpy())\n#             val_targets.append(targets.cpu().numpy())\n# #             losses.append(loss.item())\n# #             f1_Score = f1_score(output.cpu().numpy(),targets.cpu().numpy().astype(int))\n# #             f1.append(f1_Score)\n# #             if i==5:\n# #                 return  val_outputs,val_targets\n# #                 break\n# #             i+=1\n# #             print(f'Val_loss: {loss},val_f1_Score:{f1_Score}')\n#     return  val_outputs,val_targets","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:52:51.877903Z","iopub.execute_input":"2024-04-12T22:52:51.878267Z","iopub.status.idle":"2024-04-12T22:52:51.886088Z","shell.execute_reply.started":"2024-04-12T22:52:51.878238Z","shell.execute_reply":"2024-04-12T22:52:51.885103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BCE = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(15,device=device))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:52:52.473317Z","iopub.execute_input":"2024-04-12T22:52:52.473709Z","iopub.status.idle":"2024-04-12T22:52:52.478664Z","shell.execute_reply.started":"2024-04-12T22:52:52.473680Z","shell.execute_reply":"2024-04-12T22:52:52.477717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def fit(epochs,model,train_dl,val_dl):\n#     optimizer = torch.optim.AdamW(model.parameters(),lr=1e-4)\n#     history = []\n#     losses = []\n#     train_outputs = []\n#     i = 1\n#     milestones = [1500, 3000]\n#     scheduler = MultiStepLR(optimizer, milestones= milestones, gamma=0.1)\n#     model.train()\n#     for epoch in range(epochs):\n#         for batch in tqdm(train_dl):\n#             input_ids, attention_mask, targets = batch\n            \n#             input_ids = input_ids.to(device)\n#             attention_mask = attention_mask.to(device)\n#             targets = targets.to(device) \n            \n#             output = model(input_ids, attention_mask)\n            \n#             loss = BCE(output.squeeze(),targets)\n#             losses.append(loss.item())\n            \n#             optimizer.zero_grad()\n#             loss.backward()\n#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5000)\n#             optimizer.step()\n#             scheduler.step()\n            \n#             if (i % 10 == 0):\n# #                 for name, param in model.named_parameters():\n# #                     if (param.grad is not None) & (param.grad.abs().sum()>5000):\n# #                         print(name, param.grad.abs().sum())\n# #                         torch.save(model.state_dict(), 'insincere_model.pth')\n#                 f1, thres = find_best_f1(torch.sigmoid(output.detach()).squeeze().cpu().numpy(), targets.cpu().numpy())\n#                 print(f'Batch:{i} ; Loss: {loss:.3f}; Pred at {thres:.3}:{get_preds(output.squeeze(),thres)}; best_Train_f1:{f1:.3f}')\n                \n#             if (i % 10 == 0):\n#                 current_lr = optimizer.param_groups[0]['lr']\n#                 print(\"\\nCurrent learning rate:\", current_lr)\n#                 torch.save(model.state_dict(), 'insincere_model.pth')\n#             i += 1\n         \n#         val_outputs,val_targets = evaluate(model,val_dl)\n#         val_outputs = np.concatenate(val_outputs)\n#         val_targets = np.concatenate(val_targets)\n#         val_f1, threshold = find_best_f1(val_outputs, val_targets)\n#         print(\"Epoch {}; Val F1: {:.3f}, Threshold: {:.3f}\".format(epoch,val_f1, threshold))\n#     return [val_f1,threshold,val_outputs,val_targets]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:54:57.559125Z","iopub.execute_input":"2024-04-12T22:54:57.559801Z","iopub.status.idle":"2024-04-12T22:54:57.572156Z","shell.execute_reply.started":"2024-04-12T22:54:57.559768Z","shell.execute_reply":"2024-04-12T22:54:57.571193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results = fit(1,model,train_dl,val_dl) Hyper parameter tuning, getting bad results","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-12T20:02:26.438678Z","iopub.execute_input":"2024-04-12T20:02:26.439498Z","iopub.status.idle":"2024-04-12T20:55:57.630800Z","shell.execute_reply.started":"2024-04-12T20:02:26.439464Z","shell.execute_reply":"2024-04-12T20:55:57.629378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results = fit(1,model,train_dl,val_dl) #### Hyper parameter tuning (again getting bad resuts)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T21:18:36.754186Z","iopub.execute_input":"2024-04-12T21:18:36.754539Z","iopub.status.idle":"2024-04-12T22:17:10.780913Z","shell.execute_reply.started":"2024-04-12T21:18:36.754512Z","shell.execute_reply":"2024-04-12T22:17:10.779669Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results = []","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:55:24.198237Z","iopub.execute_input":"2024-04-12T22:55:24.198913Z","iopub.status.idle":"2024-04-12T22:55:24.202671Z","shell.execute_reply.started":"2024-04-12T22:55:24.198881Z","shell.execute_reply":"2024-04-12T22:55:24.201755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results.append(fit(5,model,train_dl,val_dl))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:55:25.488085Z","iopub.execute_input":"2024-04-12T22:55:25.488962Z","iopub.status.idle":"2024-04-13T02:25:07.253226Z","shell.execute_reply.started":"2024-04-12T22:55:25.488931Z","shell.execute_reply":"2024-04-13T02:25:07.251967Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model.state_dict(), 'insincere_model_final_successful.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:25:17.589585Z","iopub.execute_input":"2024-04-13T02:25:17.590281Z","iopub.status.idle":"2024-04-13T02:25:18.206038Z","shell.execute_reply.started":"2024-04-13T02:25:17.590250Z","shell.execute_reply":"2024-04-13T02:25:18.205030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results = evaluate(model,val_dl)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:27:34.518968Z","iopub.execute_input":"2024-04-13T02:27:34.519548Z","iopub.status.idle":"2024-04-13T02:38:06.458004Z","shell.execute_reply.started":"2024-04-13T02:27:34.519517Z","shell.execute_reply":"2024-04-13T02:38:06.457129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# val_outputs,val_targets = results\n# val_outputs = np.concatenate(val_outputs)\n# val_targets = np.concatenate(val_targets)\n# val_f1, threshold = find_best_f1(val_outputs, val_targets)\n# print(\"Val F1: {:.3f} at Threshold: {:.3f}\".format(val_f1, threshold))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T02:44:21.899884Z","iopub.execute_input":"2024-04-13T02:44:21.900873Z","iopub.status.idle":"2024-04-13T02:44:31.805155Z","shell.execute_reply.started":"2024-04-13T02:44:21.900838Z","shell.execute_reply":"2024-04-13T02:44:31.804217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_threshold = 0.9","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:33:17.671741Z","iopub.execute_input":"2024-04-13T21:33:17.672377Z","iopub.status.idle":"2024-04-13T21:33:17.676363Z","shell.execute_reply.started":"2024-04-13T21:33:17.672345Z","shell.execute_reply":"2024-04-13T21:33:17.675364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding = bert_tokenizer.encode_plus(\n#             \"Why are IITs so bad at research?\",\n#             max_length=60,\n#             padding='max_length',\n#             truncation=True,\n#             add_special_tokens=True,\n#             return_tensors='pt'\n#         ) ","metadata":{"execution":{"iopub.status.busy":"2024-04-13T03:03:14.235634Z","iopub.execute_input":"2024-04-13T03:03:14.235982Z","iopub.status.idle":"2024-04-13T03:03:14.241752Z","shell.execute_reply.started":"2024-04-13T03:03:14.235955Z","shell.execute_reply":"2024-04-13T03:03:14.240661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output = model(encoding['input_ids'].to(device), encoding['attention_mask'].to(device))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T03:03:15.329333Z","iopub.execute_input":"2024-04-13T03:03:15.329727Z","iopub.status.idle":"2024-04-13T03:03:15.349142Z","shell.execute_reply.started":"2024-04-13T03:03:15.329698Z","shell.execute_reply":"2024-04-13T03:03:15.348331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get_preds(output.squeeze(),0.9)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T03:03:16.149842Z","iopub.execute_input":"2024-04-13T03:03:16.150207Z","iopub.status.idle":"2024-04-13T03:03:16.158027Z","shell.execute_reply.started":"2024-04-13T03:03:16.150181Z","shell.execute_reply":"2024-04-13T03:03:16.157045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del model","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:43:26.774083Z","iopub.execute_input":"2024-04-13T19:43:26.774823Z","iopub.status.idle":"2024-04-13T19:43:27.184934Z","shell.execute_reply.started":"2024-04-13T19:43:26.774789Z","shell.execute_reply":"2024-04-13T19:43:27.183459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BERT_MODEL()\n# model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:32:58.553657Z","iopub.execute_input":"2024-04-13T21:32:58.554620Z","iopub.status.idle":"2024-04-13T21:33:02.800902Z","shell.execute_reply.started":"2024-04-13T21:32:58.554550Z","shell.execute_reply":"2024-04-13T21:33:02.800103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/insincere_question_final_model/pytorch/1.01/1/insincere_model_final_successful.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:33:02.803453Z","iopub.execute_input":"2024-04-13T21:33:02.804086Z","iopub.status.idle":"2024-04-13T21:33:06.954827Z","shell.execute_reply.started":"2024-04-13T21:33:02.804052Z","shell.execute_reply":"2024-04-13T21:33:06.953855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(df_test,model):\n    test_dataset = TestDataset(df_test,tokenizer = bert_tokenizer)\n    test_dl = DataLoader(test_dataset, batch_size = 32)\n    preds = []\n    for batch in tqdm(test_dl):\n        input_ids , attention_mask = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        output = model(input_ids, attention_mask)\n        del input_ids,attention_mask\n        prediction = (torch.sigmoid(output).squeeze() > best_threshold).int()\n        preds.append(prediction.cpu().squeeze().int().numpy())\n    print('test predictions generated successfully!!')    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:36:40.857900Z","iopub.execute_input":"2024-04-13T21:36:40.858767Z","iopub.status.idle":"2024-04-13T21:36:40.865273Z","shell.execute_reply.started":"2024-04-13T21:36:40.858735Z","shell.execute_reply":"2024-04-13T21:36:40.864217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submission(sub_df,df_test,model):\n    preds = test(df_test,model)\n    predictions = np.array([])\n    for pred in preds:\n       predictions = np.concatenate([predictions,np.array(pred)])\n    sub_df.prediction = predictions\n    print('Submission Dataframe created successfully')\n    return sub_df","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:42:51.279755Z","iopub.execute_input":"2024-04-13T21:42:51.280113Z","iopub.status.idle":"2024-04-13T21:42:51.285959Z","shell.execute_reply.started":"2024-04-13T21:42:51.280086Z","shell.execute_reply":"2024-04-13T21:42:51.284920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T21:33:06.973724Z","iopub.execute_input":"2024-04-13T21:33:06.974023Z","iopub.status.idle":"2024-04-13T21:33:07.105819Z","shell.execute_reply.started":"2024-04-13T21:33:06.974001Z","shell.execute_reply":"2024-04-13T21:33:07.104937Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = submission(sub_df,df_test,model)\nsubmission_df.prediction = submission_df.prediction.astype(int)\nsubmission_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T22:43:28.702508Z","iopub.execute_input":"2024-04-13T22:43:28.702956Z","iopub.status.idle":"2024-04-13T22:43:32.671295Z","shell.execute_reply.started":"2024-04-13T22:43:28.702923Z","shell.execute_reply":"2024-04-13T22:43:32.669692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}